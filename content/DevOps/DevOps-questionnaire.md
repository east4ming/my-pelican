Title: DevOps能力成熟度调查问卷
Category: DevOps
Tags: DevOps
Image: /images/DevOps_logo.png
Related_posts: use-ansible-manage-multi-windows

[TOC]

> :notebook: 问卷说明:
>
> 本问卷来自互联网.
> 本问卷由九个板块构成,一共73道题, 全部为单选题.

## （一）配置管理

1、版本控制系统

·       A、未使用统一的版本控制系统，源代码分散在研发本地设备管理。

·       B、使用集中式的版本控制系统并将所有源代码纳入系统管理。

·       C、使用分布式的版本控制系统，并将所有源代码、配置文件、构建和部署等自动化脚本纳入系统管理。

·       D、将数据库变更脚本和环境配置等纳入版本控制系统管理版本控制系统支持自动化的变更操作。

·       E、将软件生命周期的所有配置项纳入版本控制系统管理，可完整回溯软件交付过程满足审计要求。

2、分支管理

·       A、缺乏明确的分支管理策略，分支生命周期混乱。

·       B、采取长周期和大批量的方式进行代码提交，代码合并过程存在大量冲突和错误。

·       C、采取短分支频繁提交的方式，研究人员至少每天完成一次代码提交，代码合并过程顺畅。

·       D、分支策略满足持续交付需求，可灵活适应产品交付。

·       E、持续优化的分支管理策略，可支持团队高效协作。

3、构建产物管理

·       A、未使用统一的制品库，构建产物通过直接拷贝或本地共享等方式进行分发。

·       B、使用统一的制品库管理构建产物，有清晰的分级和目录结构及权限管控并通过单一制品库地址进行分发。

·       C、使用统一的制品库管理构建产物，并将二进制库文件和三方依赖软件工具等纳入只凭库管理。

·       D、对制品库完成分级管理，有成熟的备份恢复清理策略，如采用分布式制品库。

4、单一可信数据源

·       A、版本控制系统和制品库作为单一可信数据源，覆盖生产部署环节。

·       B、单一可信数据源进一步覆盖研发本地环境。

·       C、单一可信数据源贯穿整个研发价值流交付过程，在组织内部开放共享，建立知识积累和经验复用体系。

5、变更过程

·       A、变更过程不受控且变更信变更问题定位困难且回滚操作具有高风险分散在每个系统内部，缺乏信息的有效共享机制。

·       B、代码变更过程应附带变更管理信息。

·       C、所有配置项变更由变更管理系统触发，并作为版本控制系统的强制要求。

·       D、使用同一套变更管理系统覆盖从需求到部署发布全流程。

·       E、可视化变更生命周期，支持全程数据分析管理和满足审计要求。

6、变更追溯

·       A、变更缺乏基本的可追溯性。

·       B、有清晰定义的软件版本号规则，实现版本和代码的关联，可追溯版本构建对应的完整源代码信息。

·       C、实现版本控制系统和变更管理系统的自动化关联，信息双向同步和实时可追溯。

·       D、变更依赖被识别和标记，实现数据库和环境变更信息的可追溯。

·       E、实现从需求到部署发布各个环节的相关全部信息的全程可追溯。

7、变更回滚

·       A、变更问题定位困难且回滚操作具有高风险。

·       B、可支持版本间差异对比和代码级别问题定位和回滚。

·       C、实现变更管理系统和版本控制系统的同步回滚，保证状态的一致性。

·       D、可根据变更管理系统按需快速导出复用软件代码变更集，如建立从变更管理系统到软件代码变更集的关系数据库。

·       E、支持任何时间点全部状态的自动化回滚需求。

## （二）构建与持续集成

1、构建方式

·       A、采用手工方式进行构建，构建过程不可重复。

·       B、实现脚本自动化，通过手工配置完成构建。

·       C、定义结构化构建脚本，实现模块级共享复用和统一维护。

·       D、实现构建服务化，可按需提供接口和用户界面用于可视化构建编排。

·       E、持续优化的构建服务平台，持续改进服务易用性。

2、构建环境

·       A、使用本地设备，构建环境不可靠。

·       B、有独立的构建服务器，多种任务共享构建环境。

·       C、构建环境配置实现标准化，有独立的构建集群，单次构建控制在小时级。

·       D、优化构建速度，实现增量化构建和模块化构建，单次构建控制在分钟级，如可采用分布式构建集群、构建缓存等技术。

·       E、持续改进构建性能，实现构建资源共享和动态按需分配回收，如搭建基于云服务虚拟化和容器化的分布式构建集群。

3、构建计划

·       A、没有明确的版本号规则和构建任务计划。

·       B、明确定义版本号规则，并根据发布策略细分构建类型，实现每日自动构建。

·       C、明确定义构建计划和规则，实现代码提交触发构建和定期自动执行构建。

·       D、分级构建计划，实现按需构建并达到资源和速度的有效平衡。

·       E、分级构建计划，实现按需构建并达到资源和速度的有效平衡。

4、构建职责

·       A、构建工具和环境受限于团队人员能力，频繁手动干预维护。

·       B、构建工具和环境由专人负责维护，并使用权限隔离。

·       C、构建工具和环境由专门团队维护，并细分团队人员职责。

·       D、构建系统服务化提供更多用户使用，构建不再局限于专业团队进行。

·       E、将构建能力赋予全部团队成员，并按需触发构建实现快速反馈。

## （三）构建与持续集成

1、集成服务

·       A、没有搭建持续集成服务，团队成员缺乏对持续集成的理解。

·       B、搭建统一的持续集成服务并对系统进 行日常维护和管理。

·       C、组建专门的持续集成团队，负责优化持续集成系统和服务。

·       D、持续集成嵌入每个研发团队日常活动，实现持续集成系统服务化和自助化。

·       E、持续优化和改进团队持续集成服务，实现组织交付能力提升。

2、集成频率

·       A、长期本地开发代码集成频率几周或者几月一次。

·       B、采用团队定期统一集成的策略，代码集成频率几天或者几周一次。

·       C、研发人员至少每天向代码主干集成一次。

·       D、研发人员每天多次向代码主干集成，每次集成代价较低。

·       E、任何变更(代码，配置，环境)都会触发完整的持续集成流程。

3、集成方式

·       A、代码集成作为软件交付流程中的一个独立阶段。

·       B、在部分分支上进行每天多次的定时构建。

·       C、每次代码提交触发自动化构建，构建问题通过自动分析精准推送相关人员处理。

·       D、每次代码提交构建触发自动化测试和静态代码检查，测试问题自动上报变更管理系统，测试结果作为版本质量标准要求，如：采取质量门禁等方式强化主干代码质量。

·       E、实现持续集成分级和自动化测试分级，满足不同模块和集成阶段的差异化需求。

4、反馈周期

·       A、每次集成伴随大量的问题和冲突，集成期间主干分支长期不可用。

·       B、集成问题反馈和解决需要半天或者更长时间。

·       C、集成问题反馈和解决可以在几个小时内完成。

·       D、集成问题反馈和解决控制在 30分钟以内完成。

·       E、集成问题反馈和解决控制在 10分钟以内完成。

## （四）测试管理

1、分层方法

·       A、只进行用户/业务级的 UI 测试。

·       B、采用接口/服务级测试对模块/服务进行覆盖全面的接口测试；采用代码级测试对核心模块的函数或类方法进行单元测试；对系统进行基本的性能测试。

·       C、采用代码级测试对模块的函数或类方法进行覆盖全面的单元测试；系统全面的进行性能、容量、稳定性、可靠性、易用性、兼容性、安全性等非功能性测试。

·       D、采用测试驱动开发的方式,进行代码级、接口级测试；采用探索性测试方法对需求进行深入挖掘测试

·       E、采用验收测试驱动开发的方式进行用户/业务级的 UI测试。

2、分层策略

·       A、尚未建立测试分层策略，测试不分层。

·       B、测试开始分层，但对测试分层策略缺乏系统的规划，对用户/业务级测试、接口/服务级、代码级测试分布比例由高到低，各层测试缺乏有效的设计。

·       C、对测试分层策略进行系统的规划，用户/业务级、接口/服务级、代码级测试分布比例由低到高，充分设计;代码对非功能性测试进行全面系统的设计。

·       D、测试分层策略的各层测试具有交叉互补性。

·       E、定期验证测试分层策略，是否完整有效，持续优化策略。

3、测试时机

·       A、测试在软件交付过程中在开发完成后才介入。

·       B、测试在持续交付过程中的介入时间提前到开发的集成阶段，接口/服务级测试在模块的接口开发完成后进行。

·       C、测试在持续交付过程中的介入时间提前到开发的编码阶段，代码级测试在模块的函数或类方法开发完成后进行。

·       D、代码级测试在模块的函数或类方法开发过程中同步进行和完成；接口/服务级测试在模块的接口开发过程中同步进行和完成。

·       E、在需求阶段进行用户/业务级测定期验证测试设计，在需求特性并发、交付，整个过程中同步进行并完成测试。

4、质量规约

·       A、代码质量检查无任何规约。

·       B、代码质量检查具备基本规约，但还缺乏完整性和有效性。

·       C、代码质量检查具备完整、有效和强制执行的规约。

·       D、代码质量检查规约根据需要可进行扩展和定制。

·       E、定期验证代码质量规约的完整性和有效性，持续优化。

5、检查策略

·       A、代码质量检查无针对检查范围、质量门限等相关的策略。

·       B、代码质量检查有针对检查范围、质量门限的策略，对代码规范、错误和圈复杂度、重复度等质量指标进。行检查分析

·       C、代码质量检查将安全漏洞检查、合规检查纳入到检查范围。

·       D、代码质量检查针对检查范围、质量门限的策略可根据需要灵活调整。

·       E、定期验证代码质量策略的完整性和有效性，持续优化。

6、检查方式

·       A、代码质量检查采用人工方式进行评审。

·       B、代码质量检查采用自动化结合手工方式进行。

·       C、代码质量检查完全自动化，不需要手工干预。

·       D、对代码质量检查发现的部分问题自动提出修改建议，支持可视化。

·       E、具备企业级的代码质量管理平台，以服务的形式提供对代码质量的检查分析。

7、反馈处理

·       A、对代码质量检查结果处理不及时，遗留大量技术债。

·       B、对代码质量检查结果给出反馈，根据反馈进行处理，对遗留的部分技术债乏跟踪和管理，导致遗漏。

·       C、根据代码质量检查结果反馈及时处理，技术债仍有短期遗留，但进行有效的跟踪、管理和处理。

·       D、将检查结果强制作为版本质量标准要求，根据代码质量检查提出的修改建议，对问题及时处理，在研发阶段主动解决技术债。

·       E、对代码质量数据进行统一管理，可有效追溯并对代码质量进行有效度量。

8、自动化设计

·       A、未采用自动化方式测试，纯手工测试。

·       B、尚未对测试用例中自动化部分进行规划和设计，覆盖不完整。

·       C、根据需求、接口和代码对不同测试分层中自动化测试用例进行规划和设计，自动化覆盖比较完整。

·       D、对性能、稳定性、可靠性、安全性等非功能性测试中自动化用例进行规划和设计，自动化覆盖完整。

·       E、对故障和测试进行复盘，对遗漏的测试用例进行补充，不断优化和完善，持续提升覆盖率。

9、自动化开发

·       A、尚未对自动化测试脚本进行开发和管理，手工测试。

·       B、对自动化测试脚本进行开发和本地管理。

·       C、自动化测试脚本开发采用数据驱动、关键字驱动等方法；使用版本控制系统对自动化测试脚本进行有效管理。

·       D、自动化测试用例脚本间具备独立性和大批量执行的健壮性。

·       E、自动化脚本是测试用例设计的活文档，自动化脚本开发和测试用例设计完全统一。

10、自动化执行

·       A、手工测试执行效率低下，以周级为单位。

·       B、对用户/业务级测试采用自动化测试，自动化测试的执行效率不高，以天级为单位。

·       C、从代码级、接口级UI级测试实现了端到端的自动化测试打通；自动化测试执行效率较高，代码级测试分钟级，UI级测试小时级。

·       D、有组织级的统一自动化测试平台，和上下游需求、故障系统打通；可以根据需求针对性自动关联选择自动化测试用例脚本执行；可以将由于版和故障关联。

·       E、采用企业级统一的自动化测试平台，以云化的方式提供测试服务，进行分布式测试调度执行，提高测试执行效率和资源利用率；定期验证自动化执行策略,持续优化。

11、自动化分析

·       A、手工对测试结果进行分析判断，错误高，可信度低。

·       B、对自动化测试结果具备一定的自动判断能力，存在一定的误报，可信度不足。

·       C、对自动化测试结果具备较强的自动判断能力，误报少，可信度高。

·       D、自动化测试数据模型标准化，和上下游需求、故障等研发数据关联，可以对自动化测试效果进行度量分析。例如：需求测试覆盖率、测试通过率和测试效率等。

·       E、对自动化测试结果可以智能分析，自动分析失败用例的失败类型及原因，可以自动向故障管理系统提交故障，可信度高。

## （五）部署与发布管理

1、部署方式

·       A、运维人员手工完成所有环境的部署。

·       B、运维人员通过自动化脚本实现部署过程部分自动化。

·       C、部署和发布实现全自动化，同时支持数据库自动化部署。

·       D、部署发布服务化，实现交付团队自助一键式多环境自动化。

·       E、持续优化的部署发布模式和工具系统平台。

2、部署活动

·       A、部署过程复杂不可控，伴随大量问题和较长的停机时间。

·       B、部署过程通过流程文档定义实现标准化整体可控。

·       C、使用相同的过程和工具完成所有环境部署，一次部署过程中使用相同的构建产物。

·       D、部署过程可灵活响应业务需求变化通过合理组合高效编排。

·       E、持续部署，每次变更都触发一次自动化生产环境部署过程。

3、部署策略

·       A、采用定期大批量部署策略。

·       B、应用作为部署的最小单位，应用和数据库部署实现分离，实现测试环境的自动化部署。

·       C、可运行的环境作为部署的最小单位，应用和配置进行分离。

·       D、通过多种部署发布策略保证流程风险可控，如：蓝绿部署，金丝雀发布。

·       E、软件交付团队自主进行安全可靠的部署和发布活动。

4、部署质量

·       A、部署整体失败率较高，并且无法实现回滚，生产问题只能在线上修复，修复时间不可控。

·       B、实现应用部署的回滚操作，部署失败率中等，问题可及时修复。

·       C、部署活动集成自动化测试功能，并以测试结果为部署前置条件每次部署活动提供变更对象范围报告和测试报告。

·       D、建立监控体系跟踪和分析部署过程，出现问题自动化降级回滚，失败率较低。

·       E、持续优化的部署监控体系和测试体系，部署失败率维持在极低水平。

5、协作模式

·       A、整个软件交付过程严格遵循预先计划，存在复杂的部门间协作和等待，只有在开发完成后才进行测试和部署。

·       B、通过定义完整的软件交付过程和清晰的交付规范，保证团队之间交付的有序。

·       C、团队间交付按照约定由系统间调用完成，仅在必要环节进行手工确认。

·       D、团队间依赖解耦，可实现独立安全的自主部署交付。

·       E、持续优化的交付业务组织灵活响应业务变化改善发布效率。

6、流水线过程

·       A、软件交付过程中的大部分工作通过手工方式完成。

·       B、软件交付过程中的各个环节建立自动化能力以提升处理效率。

·       C、打通软件交付过程中的各个环节，建立全流程的自动化能力，并根据自动化测试结果控制软件交付质量。

·       D、建立可视化部署流水线，覆盖整个软件交付过程，每次变更都会触发完整的自动化部署流水线。

·       E、持续部署流水线驱动持续改进。

7、过程可视化

·       A、交付过程中的信息是封闭的，交付状态不可追溯。

·       B、交付过程在团队内部可见，信息在团队间共享，交付状态可追溯。

·       C、交付过程组织内部可见，团队共享度量指标。

·       D、部署流水线全员可见，对过程信息进行有效聚合分析展示趋势。

·       E、部署流水线过程信息进行数据价值挖掘，推动业务改进。

## （六）环境管理

1、环境类型

·       A、环境类型只有生产环境和非生产环境的划分。

·       B、IT交付过程意识到部分测试环境的重要性，开始提供功能测试环境。

·       C、持续交付过程意识到研发环境的重要性，开始提供面向各类开发者独立的研发 工作区。

·       D、全面的测试与灰度环境对于质量交付过程来说非常重要，有各类的环境类型划分，区分了开发者，技术测试及业务测试环境以及灰度发布环境等等。

·       E、根据业务与应用的需要，弹性分配各类环境。

2、环境架构

·       A、环境的构建通过人工创建完成。

·       B、环境构建通过一键化的脚本或者虚拟机来完成的，构建过程完全黑盒 化完成。

·       C、环境的构建通过资源交付平台来完成，并且底层是由云来交付。

·       D、环境的构建可以通过 Docker 容器化快速交付，低成本构建一个新的环境。

·       E、环境的构建结合底层IT资源状况，采用了各类混合IT技术，根据业务及应用架构弹性构建。

3、环境依赖与配置管理

·       A、无依赖管理，环境的管理就是一个OS的交付。

·       B、以应用为中心有OS级别的依赖和配置管理能力，比如说操作系统版本、组件版本、程序包版本等等。

·       C、以应用为中心，有服务级依赖的配置管理能力，比如说依赖的关联服务，Mysql 服务、cache 服务、关联应用服务等等。

·       D、环境和依赖配置管理可以资源化描述，类似dockerfile，大大提升其配置管理能力。

·       E、环境依赖和配置可以做到实例级的动态配置管理能力，根据业务和应用架构的变化而变化。

## （七）数据管理

1、数据来源

·       A、每次测试时手工创建数据，测试数据都是临时性的。

·       B、从生产环境导出一个子集并进行清洗后，形成基准的测试数据集，满足部分测试用例执行要求。

·       C、从生产环境导出一个子集并进行清洗后，形成基准的测试数据集，满足部分测试用例执行要求。

·       D、每个测试用例专属的测试数据都可以通过模拟或调用应用程序 API 的方式自动生成。

·       E、所有的功能、非功能测试的测试数据，都可以通过模拟、数据库转储或调用应用程序 API 的方式自动生成。

2、数据覆盖

·       A、测试数据覆盖率低，仅支持部分测试场景，无法有效支持测试工作。

·       B、测试数据覆盖主要场景，包括正常类型，错误类型以及边界类型，并进行初步的分类分级，满足不同测。试类型需要。

·       C、建立体系化测试数据，进行数据依赖管理，覆盖更加复杂的业务场景。

·       D、测试数据覆盖安全漏洞和开源合规等需求场景并建立定期更新机制。

·       E、持续优化的持续数据管理方式和策略。

3、数据独立性

·       A、测试数据没有版本控制和备份恢复机制。

·       B、测试数据有明确备份恢复机制，实现测试数据复用和保证测试一致性。

·       C、每个测试用例拥有专属的测试数据，有明确的测试初始状态测试用例的执行不依赖其他测试用例执行所。产生的数据。

·       D、通过测试数据分级，实现专属测试数据和通用测试数据的有效管理和灵活组合，保证测试数据的独立性。

·       E、通过测试数据分级，实现专属测试数据和通用测试数据的有效管理和灵活组合，保证测试数据的独立性。

4、数据安全

·       A、测试数据来源复杂，混入核心生产数据，带来信息安全风险

·       B、测试数据经过清洗，不包含敏感信息，有效避免信息安全风险。

·       C、测试数据经过清洗，不包含敏感信息，有效避免信息安全风险。

·       D、测试数据经过清洗，不包含敏感信息，有效避免信息安全风险。

·       E、测试数据经过清洗，不包含敏感信息，有效避免信息安全风险。

5、变更过程

·       A、数据变更由专业人员在后台手工完成 数据变更作为软件发布的一个独立环节，单独实施和交付

·       B、数据变更通过文档实现标准化，使用自动化脚本完成变更。

·       C、数据变更作为持续部署流水线的一个环节，随应用的部署自动化完成，无需专业人员单独执行。

·       D、应用程序部署和数据库迁移解耦，可单独执行。

·       E、持续优化的数据管理方法，持续改进数据管理效率。

6、兼容回滚

·       A、没有识别数据库和应用版本，存在不兼容风险。

·       B、建立数据库和应用的版本对应关系，并跟踪变更有效性。

·       C、每次数据变更同时提供明确的恢复回滚机制，并进行变更测试，如：提供升级和回滚两个自动化脚本。

·       D、数据变更具备向下兼容性，支持保留数据的回滚操作和零停机部署。

7、版本控制

·       A、数据变更没有纳入版本控制，变更过程不可重复。

·       B、数据变更脚本纳入版本控制，并与数据库版本进行关联。

8、数据监控

·       A、没有建立变更监控体系，变更结果不可见。

·       B、对变更日志进行收集分析，帮助问题快速定位。

·       C、对数据变更进行流程分级定义，应对不同环境下的高危操作。

·       D、对数据变更进行监控，自动发现异常变更状态。

·       E、监控数据库性能并持续优化。

## （八）度量与反馈

1、度量指标定义

·       A、度量指标没有明确定义，对度量价值的理解是模糊的。

·       B、在持续交付各个阶段定义度量指标，度量指标局限于职能部门内部。

·       C、建立跨组织度量指标，进行跨领域综合维度的度量。

·       D、整个研发团队共享业务价值导向的度量指标，实现指标的抽象分级，关注核心业务指标。

·       E、持续优化的度量指标，团队自我驱动持续改进。

2、度量指标类型

·       A、度量指标以结果指标为主，如变更频率，需求交付前置时间，变更失败率和平均修复时间。

·       B、度量指标覆盖过程指标，客观反映组织研发现状。

·       C、度量指标覆盖探索性指标，关注展示趋势和识别潜在改进。

·       D、支持改进目标和试验结果的有效反馈，用于经验积累和指导下一阶段的改进工作。

3、度量数据管理

·       A、度量数据是临时性的，没有收集管理。

·       B、度量数据的收集是离散的不连续的，历史度量数据没有进行有效理。

·       C、度量数据的收集是连续的，历史度量数据有明确的管理规则。

·       D、度量数据的收集是连续且优化的，对历史数据数据进行有效的挖掘分析。

·       E、度量数据的收集是连续且优化的，对历史数据数据进行有效的挖掘分析。

4、度量指标更新

·       A、度量指标的设立和更新是固化的，度量指标没有明确的优先级。

·       B、度量指标的设立和更新是动态的，可以按照组织需求定期变更，度量指标的优先级在团队内部可以达。

·       C、建立完整的度量体系和成熟的度量框架，度量指标的设立和更新可按需实现快速定义并纳入度量体系，推动流程的持续改进。

·       D、度量指标可基于大数据分析和人工智能自动识别推荐，并且动态调整指标优先级。

5、报告生成方式

·       A、度量报告通过手工方式生成，没有标准化的格式定义，内容缺乏细节。

·       B、度量报告以自动化方式生成，通过预定义格式和内容标准化度量报告。

·       C、度量报告进行分类分级，建立多种度量反馈渠道，内容按需生成。

·       D、建立跨组织级统一的数据度量平台，数据看板内容可定制。

·       E、持续优化的度量方法，平台和展现形式。

6、报告有效性

·       A、数据时效性无法保证节。

·       B、数据体现报告生成时间点的最新状态。

·       C、通过可视化看板实时展示数据。

·       D、通过可视化看板聚合报告内容，自动生成趋势图，进行趋势分析。

·       E、通过可视化看板聚合报告内容，自动生成趋势图，进行趋势分析。

7、报告覆盖范围

·       A、受众局限于报告生成人员及相关的小范围内部。

·       B、由预先定义的事件触发自动化报告发送，受众覆盖团队内部成员。

·       C、实现报告精准范围推送，支持主动订阅，受众覆盖跨部门团队。

·       D、多维度产品状态实时信息展示。

·       E、多维度产品状态实时信息展示。

8、反馈改进

·       A、报告发现的问题没有进行有效跟踪落实，问题长期无法改进。

·       B、测试报告中反馈的问题录入问题追踪系统，进行持续跟踪。

·       C、度量反馈问题纳入研发迭代的待办事项，作为持续改进的一部分。

·       D、度量反馈的持续改进纳入研发日常工作，预留时间处理非功能性需求和技术债务，并且识别有效改进并扩展到整个组织，作为企业级知识体系积累保留。

·       E、通过数据挖掘实现跨组织跨流程数据度量分析，分析结果作为业务决策的重要依据，帮助组织持续改进价值交付流程。

## （九）分布式应用架构

1、分布式应用数量

·       A、20个以上

·       B、10~20个

·       C、5~10个

·       D、5个以下

2、实施计划

·       A、大规模迁移

·       B、保持现状

·       C、可能回退

3、技术成熟度

·       A、稳定运行

·       B、基本成熟

·       C、前期探索

·       D、研究阶段

4、云技术

·       A、虚拟化

·       B、容器(K8S、MESOS等)

·       C、物理机

·       D、外部部署

5、管理工具

·       A、openstack系列

·       B、openshift系列

·       C、其他

5、数据库

·       A、UNIX数据库

·       B、Linux商业数据库

·       C、开源分布式数据库

·       D、开源单数据库

6、微服务框架

·       A、dobbo/dobbox

·       B、spring cloud

·       C、都用

·       D、其他

7、开发

·       A、完全敏捷

·       B、部分敏捷

·       C、传统方法

8、自动化测试

·       A、完整单元测试

·       B、部分单元测试

·       C、无单元测试

9、部署策略

·       A、灰度部署

·       B、蓝绿部署

·       C、AB部署

·       D、直接替换

10、部署工具

·       A、SSH

·       B、SALT

·       C、容器编排工具

·       D、其他

11、回滚策略

·       A、自动回滚

·       B、手工回滚

·       C、无回滚策略

12、弹性部署

·       A、自动扩容

·       B、手工扩容

·       C、无法扩容

13、部署对象

·       A、docker

·       B、war

·       C、其他

14、部署方式

·       A、虚拟化+docker

·       B、虚拟化+war

·       C、容器+docker

15、部署数量

·       A、1000+

·       B、500~1000

·       C、100~500

·       D、100以下

16、更新频率

·       A、月更新

·       B、周更新

·       C、日更新

·       D、每日多次

17、更新方式

·       A、全量更新

·       B、局部更新

18、部署工作量

·       A、比以前复杂

·       B、较以前简单

·       C、非常简单

·       D、几乎自动化

19、最大障碍

·       A、分析复杂

·       B、技术复杂

·       C、运维复杂

·       D、成本提高

·       E、其他

20、综合效果

·       A、不明显

·       B、明显提高

·       C、效果变差

·       D、部分提高
